{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499c873f-272e-487e-8f09-e0286baf3145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da6287-68d5-4f2f-b833-867d8d0c1b2c",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd25669c-0afc-4f3b-bfc9-2f47e54c63d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11215873 (42.79 MB)\n",
      "Trainable params: 11215873 (42.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# First layer: Convolutional Layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "\n",
    "# Second layer: Max Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Third layer: Flatten Layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fourth layer: Dense Layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Final layer: Output Layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.002, momentum=0.8), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8109bf-1a8c-4c0b-8b72-280872b4b2d1",
   "metadata": {},
   "source": [
    "#### Question 1: Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- `mean squared error`\n",
    "- `binary crossentropy`\n",
    "- `categorical crossentropy`\n",
    "- `cosine similarity`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32b43a5-a92b-47dc-83e8-9e67e4cc06db",
   "metadata": {},
   "source": [
    "**Answer:** Binary Crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef512b00-eb2e-494f-80a7-71f3d713cac9",
   "metadata": {},
   "source": [
    "#### Question 2: What's the number of parameters in the convolutional layer of our model? You can use the `summary` method for that:\n",
    "- 1\n",
    "- 65\n",
    "- 896\n",
    "- 11214912"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb7688-f25c-416c-b70d-e47c142e48ac",
   "metadata": {},
   "source": [
    "**Answer:** 896"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a162d42-4e71-48ee-a37d-54fd63ea5b19",
   "metadata": {},
   "source": [
    "### Generators and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a230d083-1e8e-49a7-8e65-d5192def1d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3678 images belonging to 2 classes.\n",
      "Found 918 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 50s 270ms/step - loss: 0.6923 - accuracy: 0.5372 - val_loss: 0.6836 - val_accuracy: 0.5370\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 43s 236ms/step - loss: 0.6757 - accuracy: 0.5609 - val_loss: 0.6420 - val_accuracy: 0.6166\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 59s 319ms/step - loss: 0.6593 - accuracy: 0.5957 - val_loss: 0.6188 - val_accuracy: 0.6612\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 50s 271ms/step - loss: 0.6322 - accuracy: 0.6349 - val_loss: 0.5937 - val_accuracy: 0.6688\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 52s 282ms/step - loss: 0.5971 - accuracy: 0.6805 - val_loss: 0.5646 - val_accuracy: 0.7244\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 49s 268ms/step - loss: 0.5540 - accuracy: 0.7276 - val_loss: 0.5364 - val_accuracy: 0.7429\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 52s 283ms/step - loss: 0.5258 - accuracy: 0.7471 - val_loss: 0.5348 - val_accuracy: 0.7146\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 43s 231ms/step - loss: 0.4998 - accuracy: 0.7684 - val_loss: 0.5346 - val_accuracy: 0.7244\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 44s 239ms/step - loss: 0.4768 - accuracy: 0.7909 - val_loss: 0.5331 - val_accuracy: 0.7407\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 44s 238ms/step - loss: 0.4602 - accuracy: 0.7893 - val_loss: 0.5209 - val_accuracy: 0.7549\n"
     ]
    }
   ],
   "source": [
    "train_path = 'homework_data/train'\n",
    "test_path = 'homework_data/test'\n",
    "\n",
    "# Define the ImageDataGenerator for rescaling\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setup the train and test generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,              \n",
    "    target_size=(150, 150),  # Assuming the target size is (150, 150)\n",
    "    batch_size=20,\n",
    "    class_mode='binary',     # For binary classification\n",
    "    shuffle=True             # Shuffling the data\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_path,               \n",
    "    target_size=(150, 150),  # Assuming the target size is (150, 150)\n",
    "    batch_size=20,\n",
    "    class_mode='binary',     # For binary classification\n",
    "    shuffle=True             # Shuffling the data\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f249465e-6f89-45ee-9349-5dd4b4bbda22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of Training Accuracy: 0.7040511071681976\n",
      "Standard Deviation of Training Loss: 0.08126418310341978\n"
     ]
    }
   ],
   "source": [
    "# Extract the training accuracy and loss from the history object\n",
    "training_accuracy = history.history['accuracy']\n",
    "training_loss = history.history['loss']\n",
    "\n",
    "# Calculate the median of training accuracy\n",
    "median_accuracy = np.median(training_accuracy)\n",
    "\n",
    "# Calculate the standard deviation of training loss\n",
    "std_loss = np.std(training_loss)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Median of Training Accuracy: {median_accuracy}\")\n",
    "print(f\"Standard Deviation of Training Loss: {std_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559ed45-3264-4e40-92e7-63b97e578002",
   "metadata": {},
   "source": [
    "#### Question 3: What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.20\n",
    "- 0.40\n",
    "- 0.60\n",
    "- 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b601473-83d1-4ca2-a53f-5a9a16133062",
   "metadata": {},
   "source": [
    "**Answer:** 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb4cd18-aa1d-4a23-a4e9-a52fe1370a74",
   "metadata": {},
   "source": [
    "#### Question 4: What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.031\n",
    "- 0.061\n",
    "- 0.091\n",
    "- 0.131"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c69956-59de-442b-b2a0-8a0d1b909b81",
   "metadata": {},
   "source": [
    "**Answer:** 0.091"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6998c5-a18d-4ba1-82a1-e6110042a87a",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f08c79-f796-4126-9d7e-d2278ebb8814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3678 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 59s 319ms/step - loss: 0.5071 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7636\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 59s 318ms/step - loss: 0.5037 - accuracy: 0.7626 - val_loss: 0.4929 - val_accuracy: 0.7560\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 61s 329ms/step - loss: 0.4905 - accuracy: 0.7716 - val_loss: 0.4783 - val_accuracy: 0.7745\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 58s 314ms/step - loss: 0.4877 - accuracy: 0.7727 - val_loss: 0.5174 - val_accuracy: 0.7429\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 59s 319ms/step - loss: 0.4865 - accuracy: 0.7792 - val_loss: 0.4729 - val_accuracy: 0.7778\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 55s 297ms/step - loss: 0.4819 - accuracy: 0.7781 - val_loss: 0.5172 - val_accuracy: 0.7538\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 55s 297ms/step - loss: 0.4726 - accuracy: 0.7874 - val_loss: 0.4684 - val_accuracy: 0.7821\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 54s 294ms/step - loss: 0.4744 - accuracy: 0.7838 - val_loss: 0.5293 - val_accuracy: 0.7495\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 484s 3s/step - loss: 0.4682 - accuracy: 0.7844 - val_loss: 0.4558 - val_accuracy: 0.7908\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 68s 371ms/step - loss: 0.4685 - accuracy: 0.7798 - val_loss: 0.4667 - val_accuracy: 0.7865\n"
     ]
    }
   ],
   "source": [
    "# Define the ImageDataGenerator with data augmentation for the training set\n",
    "train_datagen_augmented = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Setup the augmented train generator\n",
    "train_generator_augmented = train_datagen_augmented.flow_from_directory(\n",
    "    train_path,              \n",
    "    target_size=(150, 150),  # Assuming the target size is (150, 150)\n",
    "    batch_size=20,\n",
    "    class_mode='binary',     # For binary classification\n",
    "    shuffle=True             # Shuffling the data\n",
    ")\n",
    "\n",
    "# Continue training the model for 10 more epochs\n",
    "history_augmented = model.fit(\n",
    "    train_generator_augmented,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad22408-2e65-4dd4-8069-65a73f9ca9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of Test Loss for All Epochs: 0.48915664553642274\n",
      "Average Test Accuracy for Last 5 Epochs: 0.7725490093231201\n"
     ]
    }
   ],
   "source": [
    "# Extract the test loss and accuracy from the history_augmented object\n",
    "test_loss = history_augmented.history['val_loss']\n",
    "test_accuracy = history_augmented.history['val_accuracy']\n",
    "\n",
    "# Calculate the mean of test loss for all the epochs\n",
    "mean_test_loss = np.mean(test_loss)\n",
    "\n",
    "# Calculate the average test accuracy for the last 5 epochs (from epoch 6 to 10)\n",
    "average_test_accuracy_last_5 = np.mean(test_accuracy[-5:])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean of Test Loss for All Epochs: {mean_test_loss}\")\n",
    "print(f\"Average Test Accuracy for Last 5 Epochs: {average_test_accuracy_last_5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e302a2b2-34c4-4359-ac34-d6c55b32d21d",
   "metadata": {},
   "source": [
    "#### Question 5: What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.18\n",
    "- 0.48\n",
    "- 0.78\n",
    "- 0.1080.108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7fdac7-410f-4426-9312-08eb829f451f",
   "metadata": {},
   "source": [
    "**Answer:** 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6440c-e3c1-48f0-837a-02c412b525af",
   "metadata": {},
   "source": [
    "#### Question 6: What's the average of test accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "- 0.38\n",
    "- 0.58\n",
    "- 0.78\n",
    "- 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54812ebd-dd39-4fce-af55-f4b0b23a49d4",
   "metadata": {},
   "source": [
    "**Answer:** 0.78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
